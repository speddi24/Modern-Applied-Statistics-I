---
title: "Homework 1"
author: "Snigdha Peddi"
date: "9/5/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F,warning=F,echo=F,fig_height=10,fig_width=7,cache = F)
```

```{r libraries}

# libraries used for Homework 1

#install.packages("HSAUR3")
library(HSAUR3)
#install.packages("dplyr")
library(dplyr)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("tidyverse")
library(tidyverse)
#install.packages("MASS")
library (MASS)
#install.packages("tidyr")
library(tidyr)
#install.packages("GMCM")
library(GMCM)
```

Question 1: Calculate the median profit for the companies in the US and the median profit for the companies in the UK,France and Germany.

Answer: To answer this question I have used *dplyr* package to aggregate and summarize data. I used group by function to group the data by country and then used summarize function to calculate the median profit making sure to remove any NA values(na.rm=True) while summarizing. Then I filtered the countries, United States,United Kingdom, France and Germany.

```{r Question 1}

# Reading the file

  #data("Forbes2000")

# Checking the data

  #head("Forbes2000")

# Aggregating and Summarizing data using functions in dplyr package

Q1 <- Forbes2000 %>%
    group_by(country) %>%
    summarize( Median_Profit = median(profits, na.rm=TRUE)) %>%
    filter(country %in% c("United States","United Kingdom","France","Germany"))

# printing the summarized data

Q1
```


Question 2: Find all German companies with negative profit

Answer: I have used *dplyr* package to select the columns name, country and profits which are more relevant for this problem. Then grouped by country and filtered data where country is Germany and profits are less than zero.

```{r Question 2}

# Filtering the Germany data with negative profits using dplyr package

Q2 <-Forbes2000 %>%
    dplyr::select(name,country,profits) %>%
    group_by(country) %>%
    filter(country %in% c("Germany")) %>%
    filter (profits < 0)

# printing the summarized data

head(Q2)

```
Question 3: To which business category do most of the Bermuda island companies belong?

Answer: I have selected the relevant variables from the Forbes2000 data set. Filtered the data set by country and selected all the data that belongs to Bermuda.Then used count function from *dplyr* package to count the number of unique categories the companies of the country belong to. I have sorted that observations(count) to have highest at the top and then sliced the data set to display the category to which most of the Bermuda companies belong to.
```{r Question 3}

Q3 <- Forbes2000 %>%
    dplyr::select(name,country,category) %>%
    filter (country == "Bermuda") %>%
  # used count function to group by country and count the number of companies in each category and sorted from highest to lowest
    count(country,category, sort =TRUE) 
  # to find out the category of most Bermuda companies
    Q3 <- Q3[1,] 

# printing the summarized data   
   
Q3
```

Question 4: For the 50 companies in the Forbes data set with the highest profits,plot sales against assets(or some suitable information of each variable),labeling each point with the appropriate country name which may need to be abbreviated(using abbreviate)to avoid making the plot look too 'messy'.

Answer: For this Question, I have used functions, select and arrange from *dplyr* package. I have selected relevant variables and used arrange function to sort the data set from highest profits to lowest profits. Subset top 50 rows to have top 50 profit making companies. Used this Subset of data to plot Sales vs assets using base R function and also using ggplot.Used geom_text to add abbreviated country labels.As the plot is overcrowded, zoomed the plot to see the trend by resetting the scale of x axis to 0 and 75 and y axis to 0 and 800. 

```{r Question 4}

# Arranging data set to highest to lowest profits

Q4.1 <- Forbes2000 %>% dplyr::select(country,name,profits,sales,assets) %>% arrange(desc(profits)) 

# Subsetting top 50 rows to show top 50 profit making companies.

Q4.1 <- Q4.1[1:50,]

```

```{r}

# Plotting Sales against assets using basic R plot function

Q4.2 <- plot(Q4.1$sales,Q4.1$assets,
      main="Forbes2000_Sales vs Assets",
      xlab="Sales",
      ylab="Assets",
      col=Q4.1$country,
      pch=16,cex=0.3)
# Add legend to top right, outside plot region
legend("topright",legend=unique(Q4.1$country),col=Q4.1$country,pch=16,cex=0.6,title="Country")
text(Q4.1$sales,Q4.1$assets,abbreviate(Q4.1$country,minlength=2),cex=0.6,col=as.numeric(Q4.1$country))


# Plotting Sales against assets using ggplot

gg4.1 <-ggplot(Q4.1,aes(x=Q4.1$sales,y=Q4.1$assets))+geom_point(aes(col=country))+
  labs(title="Forbes2000_Sales vs Assets",x="Sales",y="Assets")+
  geom_text(aes(label=abbreviate(Q4.1$country,2)),position = position_dodge(width=0.9),size=2)

plot(gg4.1)

# As the plot is overcrowded, zooming in the plot to see the trend 

gg4.2 <-ggplot(Q4.1,aes(x=Q4.1$sales,y=Q4.1$assets))+geom_point(aes(col=country))+
  labs(title="Forbes2000_Sales vs Assets:Zoomed",x="Sales",y="Assets")+
  geom_text(aes(label=abbreviate(Q4.1$country,2)),position = position_dodge(width=0.9),size=3)+
  xlim(0,75)+
  ylim(0,800)

plot(gg4.2)
```

Question 5: Find the average values of sales for the companies in each country in the Forbes data set, and find the number of companies in each country with profits above 5 billion US dollars

Answer: Grouped the data by country and then computed the mean sales using summarize function. Filtered the Forbes data to get the companies making profits over 5 billion, grouped by country,summarized the length of the companies and arranged by highest at the top.

```{r}
# Grouping the data by country and computing the average sales
Q5.1 <- Forbes2000 %>%
    group_by(country) %>%
    summarize(avg_sales = mean(sales))

# printing top 6 observations
head(Q5.1)

# Finding number of companies in each country with profits above 5 billion and sorting with hightes profits at the top

Q5.2 <- Forbes2000 %>% filter(profits> 5,!is.na(profits)) %>% group_by(country) %>% summarise( n=length(name)) %>% arrange(desc(n))
head(Q5.2)
```

Question 6: The data in the household data table are part of a data set collected from a survey of household expenditure and give the expenditure of 20 single men and 20 single women on four commodity groups. The units of expenditure are Hong Kong dollars, and the four commodity groups are housing housing,including fuel and light food foodstuffs,including alcohol and tobacco,goods other goods,including clothing,footwear,and durable goods,service services,including transport and vehicles.The aim of the survey was to investigate how the division of household expenditure between the four commodity groups depends on total expenditure and to find out whether this relationship differs for men and women.Use appropriate graphical methods to answer these questions and state your conclusions.

Answer:

### Plot 1 and Plot 2
To answer this question, first I have used mutate function from *dplyr* package to compute the percent expenditure of four commodities against the total expenditure. Then used gather function from *tidyr* package to convert the data from wide form to long form with categorical variables to commodity and percentage values to Percent_Expenditure.
     Verified the data and Used ggplot to geom_bar to plot a barplot with Percent expenditure on Y axis and Commodities on X axis, and facet wrapped by gender. This plot clearly shows that the amount of money spent by Males and Females differs between each commodity. For example, males tend to spend more on services whereas females tend to spend more on housing.Then,plotted total_expenditure on Y axis and gender on X axis to investigate the spending behavior of males vs females and it was observed that on average males spend more than females.

### Plot 3  
  To show the relationship between the Total Expenditure and household expenditure I used a scatter plot between Total_Expenditure vs commodity. For this purpose, used mutate function to compute total expenditure and converted the data into long form using gather function. The final plot clearly shows that as the total expenditure increases the household service expenditure also increases (shown by very less smoothing around the linear plot). At the same time the relation between food expenditure and the total expenditure cannot be clearly determined as shown by the line that does not fit properly.   Additionally the relationship between total expenditure and food expenditures cannot be determined because the data does not fit a line.The other two variables do increase with the total expenditure but not same as services.
  
### Plot 4 and Plot 5
 To show the relationship between the expenditure behavior based on gender I have plotted density plot between Expenditure and wrapped by gender. It clearly shows that most of the females spend less on food and more on housing. Whereas, males spend more on food and less on goods.In the last plot, we will examine the density curves of each expenditure by gender.The last plot was zoomed in to show the expenditure patter clearly.

```{r Question 6}

# using mutate function to compute % expenditure per commodity and total_expenditure
household.dat <- household %>% mutate(food =(food/(housing + food+ goods + service))*100) %>% mutate(housing= (housing/(housing + food+ goods + service))*100) %>% mutate(goods= (goods/(housing + food+ goods + service))*100) %>% mutate(service= (service/(housing + food+ goods + service))*100)%>% mutate(Total_Expenditure= (housing + food+ goods + service))
#head(household.dat)

# using gather function to convert the data from wide form to long form
household.dat_long <- gather(household.dat,commodity ,Percent_Expenditure, housing:service, factor_key=TRUE)
#head(household.dat_long)

# plotting commodity vs Percent_Expenditure and wrapping by gender using ggplot
gg6.1 <-ggplot(household.dat_long,aes(y=Percent_Expenditure,x=commodity,fill=commodity))+
  geom_bar(stat='identity')+
labs(title="Household Expenditure",x="Commodity",y="% Expenditure")+
facet_wrap(~gender,ncol=1)
plot(gg6.1)  

# plotting Gender vs Total_Expenditure and wrapping by gender using ggplot
gg6.2 <-ggplot(household.dat_long,aes(y=Total_Expenditure,x=gender,fill=gender))+
  geom_bar(stat='identity')+
labs(title="Household Total Expenditure by Gender",x="Gender",y="Total Expenditure")
 plot(gg6.2)

# using mutate function to compute total_expenditure
household.dat2 <- household %>% mutate(Total_Expenditure= (housing + food+ goods + service))
#head(household.dat2)

# using gather function to convert the data from wide form to long form
household.dat_long2<- gather(household.dat2,commodity ,Expenditure, housing:service, factor_key=TRUE)
#household.dat_long2

#plotting Total expenditure vs expenditure per commodity using ggplot
gg6.3 <-ggplot(household.dat_long2,aes(y=Total_Expenditure,x=Expenditure))+
  geom_point(aes(col=commodity))+
  geom_smooth(method="lm")+
labs(title=" Individual Household Expenditure",x="Commodity",y="Total Expenditure")+
facet_wrap(~commodity,ncol=1)
plot(gg6.3)  

# plotting density plot for Expenditure per commodity and wrapping them by gender
gg6.4 <-ggplot(household.dat_long2,aes(x=Expenditure,color=commodity))+
  geom_density()+
  #geom_smooth(method="lm")+
labs(title="Household Expenditure:Density by Gender",x="Expenditure",y="Density")+
facet_wrap(~gender,ncol=2)
plot(gg6.4) 

# Zooming in to investigate the expenditure behaviors by gender using density plot
gg6.4.2 <-ggplot(household.dat_long2,aes(x=Expenditure,color=commodity))+
  geom_density()+
  #geom_smooth(method="lm")+
labs(title="Household Expenditure:Density by Gender",x="Expenditure",y="Density")+
facet_wrap(~gender,ncol=2)+
  xlim(0,2200)
plot(gg6.4.2)
```
Question 7: Mortality rates per 100,000 from male suicides for a number of age groups and a number of countries are given.Construct side by side box plots for the data from different age groups, and comment on what the graphics tells us about the data.

Answer: For this question, first the column names were changed and then the numerical columns were stacked one over the other using stack function. The resulting data set has numerical values as values and age group as ind.Used basic boxplot function to plot suicide rate vs age group.
Below are few of my observations,
   * A lowest mortality rate of about 5 is observed in age groups 25-34 and highest is observed in age group 55-64.
   * Mortality rate of age groups 35-44 is between 8 and 42 (with one outlier with a rate about 65).With a lower overall mortality rate compared to other age groups.
   * Mortality rate of age groups 55-64 is between 14 and 80 ,With a higher overall mortality rate compared to other age groups. However there is an outlier in the age groups 65-74 where the mortality rate is above 100.
   * The boxplot for age group 35-44, with a median in the center demonstrates that mortality rate is below ~25 for 50% observations and above ~25 for the rest and the distribution is condense and can be predicted with more confidence than other age groups.
   * The median is at about the center of the boxplot for age groups 55-64.However, the 4th quartile indicates that the rate is wide spread.
   * For the age group 65-74, the lowest mortality rate is above 20 indicating that for this age group all the countries have mortality rate of more than 20 which is higher than other age groups.

```{r Question 7}
# Renamed the columns for clarity
suicide.dat <- suicides2 %>% rename("25-34"=A25.34 ,"35-44"=A35.44,"45-54"=A45.54,"55-64"=A55.64,"65-74"=A65.74 )
#suicide.dat <- suicide2[,-1]
#Stacked the numerical variables one over the other 
suicide.dat <- data.frame(stack(suicide.dat[1:5]))

#head(suicide.dat)

# boxplot between suicide rate and the age group using basic R function
boxplot(suicide.dat$values~suicide.dat$ind, 
        xlab="Age Groups",
        ylab="Mortality Rate",
        main=" Comparision of Mortality rate")

#boxplot between suicide rate and the age group using ggplot
ggplot(suicide.dat,aes(suicide.dat$ind , suicide.dat$values)) + geom_boxplot(outlier.colour = "red", outlier.shape = 1)+
  labs(title="Comparision of Mortality rate",x="Age Groups", y = "Mortality Rate")
```

Question 8. Using a single R statement, calculate the median absolute deviation, $1.4826\cdot median|x-\hat{\mu}|$, where $\hat{\mu}$ is the sample median. Use the dataset \textbf{chickwts}. Use the R function `mad()` to verify your answer.

Answer: Manually calculated the mean absolute deviation of weights variable of chcikwts dataset. The result is same compared to mean absolute deviation derived by using mad function.
```{r Question 8}
chick <- chickwts

Mean_absolute_deviation <- (1.4826 *median(abs(chick$weight-median(chick$weight))))
Mean_absolute_deviation

# Mean absolute deviation calculated using mad function
mad(chick$weight)
```

Question 9. Using the data matrix \textbf{state.x77}, find the state with the minimum per capita income in the New England region as defined by the factor \textit{state.division}. Use the vector \textit{state.name} to get the state name.

Answer:To answer this question, first the vectors state.name and state.division were added to the state.x77 data set by using cbind function.Per capita income was computed and added as a new variable to the dataset.Then,functions filter,arrange,select functions from *dplyr* package were used to filter the New England state division,arranged the per capita incoome by descending order and selected relevant variables to find the state with minimum per capita income.

```{r Question 9}
# converting the vector state.division to data frame
new_df <- as.data.frame(state.division)
# Binding by column
New_matrix <- cbind(state.x77,new_df,state.name)
# Computing per capita income and adding it as a new column
New_matrix$Per_capita_income <- (New_matrix$Income/New_matrix$Population)


Q9 <- New_matrix %>% filter(state.division == "New England") %>% arrange(desc(Per_capita_income)) %>% tail(1) %>% dplyr::select(state.name,state.division,Per_capita_income)
# Removing rownames
Q9 <- remove_rownames(Q9)

Q9

```

Question 10. Use subsetting operations on the dataset \textbf{Cars93} to find the vehicles with highway mileage of less than 25 miles per gallon (variable \textit{MPG.highway}) and weight (variable \textit{Weight}) over 3500lbs. Print the model name, the price range (low, high), highway mileage, and the weight of the cars that satisfy these conditions.

Answer: Using the standard subsetting functions subset relevant variables and filtered vehicles with highway mileage less than 25 miles per gallon and weight over 3500lbs. Then, using *dplyr* arrange function sorted the vehicles by weight and pronted the head of dataset.

```{r Question 10}
Q10 <- Cars93

# Subset the relevant variables
Q10 <- Q10[c('Model','Min.Price','Max.Price','MPG.highway','Weight')]

# finding vehicles with highway mileage  less than 25 miles per gallon and weight over 3500lbs
Q10 <- Q10[Q10$MPG.highway<25 & Q10$Weight> 3500,]

Q10 %>% arrange(desc(Q10$Weight)) %>% head()

```

Question 11. Form a matrix object named \textbf{mycars} from the variables \textit{Min.Price, Max.Price, MPG.city, MPG.highway, EngineSize, Length, Weight} from the \textbf{Cars93} dataframe from the \textbf{MASS} package. Use it to create a list object named \textit{cars.stats} containing named components as follows:
 
Answer: Using *dplyr* ,select function selected relevant variables from the Cars93 dataset. Then converted to a matrix object.
 a) Created a vector of means of all variables called Cars.Means using colMeans function.
 b) Calculated the number of observations first, then using colSDS function from *GMCM* package calculated standard deviation of all columns and finally calculated standard errors of mean by dividing standard deviation with number of observations and created a vector object called Cars.Std. Errors.
 c) Created a list object of Cars.Means and Cars.Std.Errors.


```{r Question 11}

# Filtering relevant variables
mycars <- Cars93 %>% dplyr::select(Min.Price,Max.Price,MPG.city,MPG.highway,EngineSize,Length,Weight)
# Converting into a matrix object
mycars <- data.matrix(mycars)
# Check the class of the dataset
 #class(mycars)
# To Verify the data set
#head(mycars)
```

a) A vector of means, named \textit{Cars.Means}
```{r}
# creating a vector of means of all columns
Cars.Mean <- colMeans(mycars)
Cars.Mean

```

b) A vector of standard errors of the means, named \textit{Cars.Std.Errors}

```{r}
# Calculating square root of number of observations
n <- sqrt(dim(mycars)[1])
# calculating Standard deviation of all columns
col_stdev <- GMCM:::colSds(mycars)
# Calculating Standard errors of the means
Cars.Std.Errors <- (col_stdev/n)
Cars.Std.Errors
```
c) create a list object cars.stats
```{r}
# creating a list object  
cars.stats <- list(Cars.Mean,Cars.Std.Errors)
cars.stats
```

Question 12. Use the \texttt{apply()} function on the three-dimensional array \textbf{iris3} to compute:

Answer:  
         a) Computed sample means of variables Sepal Length, Sepal Width, Petal Length, Petal Width for all the species Setosa, Versicolor, Virginica using apply function.
         b) Computed sample means for whole dataset using apply function

a) Sample means of the variables \textit{Sepal Length, Sepal Width, Petal Length, Petal Width}, for each of the three species \textit{Setosa, Versicolor, Virginica}
    
```{r Question 12}
Sample_means <- apply(iris3,c(2,3), mean)
Sample_means
```

b) Sample means of the variables \textit{Sepal Length, Sepal Width, Petal Width} for the entire data set.
    
```{r}
Sample_means_dataset <- apply(iris3,2, mean)
Sample_means_dataset
```

Question 13. Use the data matrix \textbf{state.x77} and the \texttt{tapply()} function to obtain:

Answer:

    a) Converted the factor state.region into a data frame and binded factors state.name, state.division, state.region by column to state.x77 dataset.Computed Per capita income and added the new variable to the dataset.Used tapply function to compute mean per capita income of all states in individual division.
    b)Using tapply computed max function on illiteracy rate of all states in the division.
    c)Using tapply computed length of states in all regions to determine number so states per region.

a) The mean per capita income of the states in each of the four regions defined by the factor \textit{state.region}
    
```{r Question 13}
# Converting factor state.region into data frame
new_df2 <- as.data.frame(state.region)
#Binding factors state.name, state.division, state.region by column to state.x77 dataset
Q13<- cbind(state.x77,new_df2,state.name,state.division)
#Computing and adding Per capita income variable to the dataset
Q13$Per_capita_income <- (Q13$Income/Q13$Population)
# Using tapply function to compute mean per capita income of all states in individual division
tapply(Q13$Per_capita_income,Q13$state.region,mean)
```

b) The maximum illiteracy rates for states in each of the nine divisions defined by the factor \textit{state.division}
    
```{r}
tapply(Q13$Illiteracy,Q13$state.division,max)
```

c) The number of states in each region

```{r}
tapply(Q13$state.name,Q13$state.region,length)
```

    
Question 14. Using the dataframe \textbf{mtcars}, produce a scatter plot matrix of the variables \textit{mpg, disp, hp, drat, qsec}. Use different colors to identify cars belonging to each of the categories defined by the \textit{carsize} variable in different colors.

Answer: Categorized the cars by car weight as Compact,Midsize and Large and saved as a vector carsize. Selected the relevant variables and added carsize variable to dataset.Defined vector, col for assigning different colors to cars by carsize.Plotted Scattor plot matrix using pairs function on the newly created dataset without carsize variable.


```{r Question 14}
# Categorizing the cars by car weight 
carsize = cut(mtcars[,"wt"], breaks=c(0, 2.5, 3.5, 5.5), 
     labels = c("Compact","Midsize","Large"))
# Selecting relevant variables
cars <- mtcars %>% dplyr::select(mpg,disp,hp,drat,qsec)
# Adding carsize variable to dataset
cars$carsize <- carsize
# Defining colors to cars by car size
col=c('red','green','blue')[cars$carsize]
# Scatter plot matrix using pairs 
pairs(cars[,-6],col=col)

#pairs(iter.dat, pch=16, col=rgb(red = 1, 0, 0, alpha = .1))
```
    
Question 15. Use the function \texttt{aov()} to perform a one-way analysis of variance on the \textbf{chickwts} data with \textit{feed} as the treatment factor. Assign the result to an object named \textit{chick.aov} and use it to print an ANOVA table.
 
Answer 15: Applied aov function of weight and feed column of chickwts dataset and printed the ANOVA table.
```{r Question 15}
chick.aov <- aov(weight~feed,data=chickwts)
chick.aov
#summary(chick.aov)
```

Question 16. Write an R function named \texttt{ttest()} for conducting a one-sample t-test. Return a list object containing the two components: 

    - the t-statistic named T;
    
    - the two-sided p-value named P.
    
Use this function to test the hypothesis that the mean of the \textit{weight} variable (in the \textbf{chickwts} dataset) is equal to 240 against the two-sided alternative. \textit{For this problem, please show the code of function you created as well as show the output. You can do this by adding} `echo = T` \textit{to the code chunk header.}

Answer 16:a) Defined a R function ttest() with variables x,y,mu(mean),alternative parameters that returns a list object containing t-statistic(T) value and two-sided p-value(P).t-statistic(T) value is computed using t.test fucntion and return the statistics and two-sided p-value(P) is coputed using t.test function and returns p.value.
b) Tested the hypothesis mu =240 and mu=0. Afer applying the ttest function it is clear that when compared to the two sided test that the hypothetical mean is not a good approximation of the mean because of the low t statistic, high p value, and the mean is outside of the 95% CI of the two sided test.
c) Then I verified the results using the inbuilt function t.test in both cases. And the results were observed to similar.

```{r, echo = T}
# creating function ttest()
ttest <- function(x,y=NULL,mu=0,alternative = 'two.sided'){
    T <- t.test(x=x,y=y,mu=mu,alternative=alternative)$statistic
    P <- t.test(x=x,y=y,mu=mu,alternative=alternative)$p.value
    result=list(T=T,P=P)
    return(result)
}

cat('T Test at mu = 240\n')
ttest(x=chickwts$weight,mu=240,alternative='two.sided')
# verifying the results using t.test function
t.test(chickwts$weight,mu=240)

cat('T Test at mu = 0\n')
ttest(x=chickwts$weight,mu=0,alternative='two.sided')
# verifying the results using t.test function
t.test(chickwts$weight,mu=0)
```


